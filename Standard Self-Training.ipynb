{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project\n",
    "## Self-labeled techniques for semi-supervised learning\n",
    "<div style=\"text-align: right\">\n",
    "    Mark Laane <br />\n",
    "    Rome, 2017\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction ###\n",
    "The aim of this project is to reimplement some techniques surveyed by Isaac Triguero et. al in paper [1] and to independently reproduce the reported results.\n",
    "\n",
    "Two self-labeled techniques are chosen: Standard Self-Training and Tri-Training. Those techniques are used on Bupa and Abalone datasets. For implementation, Python programming language was chosen along with Pandas and Sclearn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented self-labeled algorithms ###\n",
    "Two algorithms are implemented: Standard Self-Training and Tri Training.\n",
    "#### Standard Self-Training ####\n",
    "Implementation: [Standard Self-Training](StandardSelfTraining.py)\n",
    "The implementation is based on description of the algorithm in paper [2].\n",
    "Training an Standard Self-Training classifier is an iterative process - The base classifier is trained with initial labeled samples. Then it is used for labelling the unlabelled samples and the classifier is retrained with the most confident predictions. The process is repeated until the classifier output stabilizes.\n",
    "#### Tri-Training ###\n",
    "Implementation: [Tri-Training](tri_training.py)\n",
    "The implementation is based on description of the algorithm in paper [3].\n",
    "In Tri-Training, Three base classifiers is trained on randomly subsampled sets of the labelled data. Then each of them will be iteratively trained on labeled data gained from two other base classifiers. The prediciton is made by using majority voting on three base classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StandardSelfTraining import StandardSelfTraining\n",
    "from tri_training import TriTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classifiers ###\n",
    "4 different base classifiers are used. The base classifiers are provided by Sklearn library. The classifiers are configured according to the parameters described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class base_classifiers:\n",
    "    KNN = KNeighborsClassifier(\n",
    "        n_neighbors=3,\n",
    "        metric=\"euclidean\",\n",
    "        #n_jobs=2  # Parallelize work on CPUs\n",
    "    )\n",
    "    NB = GaussianNB(\n",
    "        priors=None\n",
    "    )\n",
    "    SMO = SVC(\n",
    "        C=1.0,\n",
    "        kernel='poly',\n",
    "        degree=1,\n",
    "        tol=0.001,\n",
    "        # Epsilon parameter missing?\n",
    "    )\n",
    "    CART = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        # splitter='best',\n",
    "        # max_depth=None,\n",
    "        # min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        # min_weight_fraction_leaf=0.0,\n",
    "        # max_features=None,\n",
    "        # random_state=None,\n",
    "        # max_leaf_nodes=None,\n",
    "        # min_impurity_split=1e-07,\n",
    "        # class_weight=None,\n",
    "        # presort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, 8 classifiers are trained - 2 techniques with 4 different base classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All classifiers used for testing\n",
    "classifiers = [\n",
    "    TriTraining(\"TriTraining (KNN)\", base_classifiers.KNN),\n",
    "    TriTraining(\"TriTraining (NB)\", base_classifiers.NB),\n",
    "    TriTraining(\"TriTraining (SVM)\", base_classifiers.SMO),\n",
    "    TriTraining(\"TriTraining (CART)\", base_classifiers.CART),\n",
    "    StandardSelfTraining(\"Self-Training (KNN)\", base_classifiers.KNN),\n",
    "    StandardSelfTraining(\"Self-Training (NB)\", base_classifiers.NB),\n",
    "    StandardSelfTraining(\"Self-Training (SVM)\", base_classifiers.SMO),\n",
    "    StandardSelfTraining(\"Self-Training (CART)\", base_classifiers.CART)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets ###\n",
    "In this project two standard datasets are used: Bupa and Abalone. They are obtained from KEEL-dataset repository. The datasets have 4 different labelling ratios: 10%, 20%, 30% and 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_datasets = \"../Datasets/\"\n",
    "\n",
    "# All datasets used for testing\n",
    "dataset_names = [\"bupa\", \"abalone\"]\n",
    "labeling_rates = [10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading the datasets, pandas library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_dataset(path):\n",
    "    \"\"\"Load one dataset\"\"\"\n",
    "    return pd.read_csv(path, header=None, sep=\", \", engine=\"python\", comment=\"@\")\n",
    "\n",
    "def load_datasets(dataset_name, labeling_rate=10):\n",
    "    \"\"\" Load 3 datasets: training, transitive and testing\"\"\"\n",
    "    partial_path=\"{0}SSC_{1}labeled/{2}/{2}-10-1\".format(path_to_datasets, labeling_rate,dataset_name)\n",
    "    dataframes = {t: load_dataset(partial_path+t+\".dat\") for t in [\"tra\", \"trs\", \"tst\"]}\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and scoring ###\n",
    "The classifier is trained on training dataset that. Then its transitive classifying perfomance is measured on the same dataset. Finally testing dataset is used to measure the performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_score(clf, dataframes,categorical=[]):\n",
    "    \"\"\"\n",
    "    Given a classifier and a datasets\n",
    "    Trains the classifier on training dataset\n",
    "    and scores the classifier on transitive and testing datasets\n",
    "    \"\"\"\n",
    "    training = dataframes[\"tra\"]\n",
    "    \n",
    "    Xtra = training.iloc[:,:-1]\n",
    "    ytra = training.iloc[:, -1]\n",
    "    Xtra = pd.get_dummies(Xtra, columns = categorical )\n",
    "    clf.fit(Xtra, ytra)\n",
    "    transitive = dataframes[\"trs\"]\n",
    "    Xtrs = transitive.iloc[:,:-1]\n",
    "    ytrs = transitive.iloc[:, -1].astype(str)\n",
    "    Xtrs = pd.get_dummies(Xtrs, columns = categorical )\n",
    "    transitive_score = clf.score( Xtrs, ytrs)\n",
    "    testing = dataframes[\"tst\"]\n",
    "    Xtst = testing.iloc[:,:-1]\n",
    "    ytst = testing.iloc[:, -1].astype(str)\n",
    "    Xtst = pd.get_dummies(Xtst, columns = categorical )\n",
    "    testing_score = clf.score(Xtst, ytst)\n",
    "    return (transitive_score, testing_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main loop of the program, that trains all the classifiers with different labelling ratios and records the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriTraining (KNN)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "--------\n",
      "TriTraining (NB)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n",
      "TriTraining (SVM)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n",
      "TriTraining (CART)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##\n",
      "--------\n",
      "Self-Training (KNN)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n",
      "Self-Training (NB)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n",
      "Self-Training (SVM)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n",
      "Self-Training (CART)\n",
      "dataset: bupa \t####\n",
      "dataset: abalone \t####\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "#Columns in datasets that are categorical and need o be replaced with hot-one\n",
    "categorical_columns = [[], [0]]\n",
    "results = pd.DataFrame(columns=('classifier', 'dataset', 'labeling_rate', \"transitive_accuracy\", \"testing_accuracy\"))\n",
    "for classifier in classifiers:\n",
    "    print(classifier.name)\n",
    "    for dataset_name, categorical in zip(dataset_names, categorical_columns):\n",
    "        print(\"dataset:\", dataset_name, \"\\t\", end=\"\")\n",
    "        for labeling_rate in labeling_rates:\n",
    "            print(\"#\", end=\"\")\n",
    "            dataframes = load_datasets(dataset_name, labeling_rate)          \n",
    "            transitive_score, testing_score = train_and_score(classifier, dataframes, categorical=categorical)\n",
    "            results.loc[len(results.index)] = [classifier.name, dataset_name, labeling_rate, transitive_score, testing_score]\n",
    "        print()\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset</th>\n",
       "      <th>labeling_rate</th>\n",
       "      <th>transitive_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>bupa</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>bupa</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.687097</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>bupa</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>bupa</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          classifier  dataset  labeling_rate  transitive_accuracy  \\\n",
       "0  TriTraining (KNN)     bupa           10.0             0.645161   \n",
       "1  TriTraining (KNN)     bupa           20.0             0.687097   \n",
       "2  TriTraining (KNN)     bupa           30.0             0.664516   \n",
       "3  TriTraining (KNN)     bupa           40.0             0.690323   \n",
       "4  TriTraining (KNN)  abalone           10.0             0.000000   \n",
       "\n",
       "   testing_accuracy  \n",
       "0          0.571429  \n",
       "1          0.600000  \n",
       "2          0.485714  \n",
       "3          0.485714  \n",
       "4          0.203349  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are organized in a table similar to the on in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">transitive_accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">testing_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>labeling_rate</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "      <th>30.0</th>\n",
       "      <th>40.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "      <th>30.0</th>\n",
       "      <th>40.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">abalone</th>\n",
       "      <th>Self-Training (CART)</th>\n",
       "      <td>0.234321</td>\n",
       "      <td>0.292689</td>\n",
       "      <td>0.330845</td>\n",
       "      <td>0.266525</td>\n",
       "      <td>0.162679</td>\n",
       "      <td>0.215311</td>\n",
       "      <td>0.177033</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (KNN)</th>\n",
       "      <td>0.222044</td>\n",
       "      <td>0.243597</td>\n",
       "      <td>0.278859</td>\n",
       "      <td>0.309701</td>\n",
       "      <td>0.169856</td>\n",
       "      <td>0.177033</td>\n",
       "      <td>0.191388</td>\n",
       "      <td>0.215311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (NB)</th>\n",
       "      <td>0.135041</td>\n",
       "      <td>0.057097</td>\n",
       "      <td>0.077313</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.126794</td>\n",
       "      <td>0.057416</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (SVM)</th>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.191569</td>\n",
       "      <td>0.194615</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.184211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (CART)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.435235</td>\n",
       "      <td>0.203349</td>\n",
       "      <td>0.222488</td>\n",
       "      <td>0.177033</td>\n",
       "      <td>0.203349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (KNN)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251601</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.332889</td>\n",
       "      <td>0.203349</td>\n",
       "      <td>0.191388</td>\n",
       "      <td>0.229665</td>\n",
       "      <td>0.239234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (NB)</th>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.107791</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.114339</td>\n",
       "      <td>0.107656</td>\n",
       "      <td>0.124402</td>\n",
       "      <td>0.117225</td>\n",
       "      <td>0.141148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (SVM)</th>\n",
       "      <td>0.214839</td>\n",
       "      <td>0.192369</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>0.210554</td>\n",
       "      <td>0.208134</td>\n",
       "      <td>0.191388</td>\n",
       "      <td>0.200957</td>\n",
       "      <td>0.193780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">bupa</th>\n",
       "      <th>Self-Training (CART)</th>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (KNN)</th>\n",
       "      <td>0.616129</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (NB)</th>\n",
       "      <td>0.487097</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>0.477419</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (SVM)</th>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (CART)</th>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.732258</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (KNN)</th>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.687097</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (NB)</th>\n",
       "      <td>0.622581</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (SVM)</th>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             transitive_accuracy                      \\\n",
       "labeling_rate                               10.0      20.0      30.0   \n",
       "dataset classifier                                                     \n",
       "abalone Self-Training (CART)            0.234321  0.292689  0.330845   \n",
       "        Self-Training (KNN)             0.222044  0.243597  0.278859   \n",
       "        Self-Training (NB)              0.135041  0.057097  0.077313   \n",
       "        Self-Training (SVM)             0.191353  0.191569  0.194615   \n",
       "        TriTraining (CART)              0.000000  0.000000  0.375100   \n",
       "        TriTraining (KNN)               0.000000  0.251601  0.300986   \n",
       "        TriTraining (NB)                0.108887  0.107791  0.099174   \n",
       "        TriTraining (SVM)               0.214839  0.192369  0.215942   \n",
       "bupa    Self-Training (CART)            0.658065  0.670968  0.625806   \n",
       "        Self-Training (KNN)             0.616129  0.667742  0.670968   \n",
       "        Self-Training (NB)              0.487097  0.480645  0.480645   \n",
       "        Self-Training (SVM)             0.683871  0.696774  0.690323   \n",
       "        TriTraining (CART)              0.693548  0.693548  0.732258   \n",
       "        TriTraining (KNN)               0.645161  0.687097  0.664516   \n",
       "        TriTraining (NB)                0.622581  0.500000  0.564516   \n",
       "        TriTraining (SVM)               0.690323  0.693548  0.696774   \n",
       "\n",
       "                                       testing_accuracy                      \\\n",
       "labeling_rate                     40.0             10.0      20.0      30.0   \n",
       "dataset classifier                                                            \n",
       "abalone Self-Training (CART)  0.266525         0.162679  0.215311  0.177033   \n",
       "        Self-Training (KNN)   0.309701         0.169856  0.177033  0.191388   \n",
       "        Self-Training (NB)    0.056770         0.126794  0.057416  0.064593   \n",
       "        Self-Training (SVM)   0.195096         0.188995  0.188995  0.184211   \n",
       "        TriTraining (CART)    0.435235         0.203349  0.222488  0.177033   \n",
       "        TriTraining (KNN)     0.332889         0.203349  0.191388  0.229665   \n",
       "        TriTraining (NB)      0.114339         0.107656  0.124402  0.117225   \n",
       "        TriTraining (SVM)     0.210554         0.208134  0.191388  0.200957   \n",
       "bupa    Self-Training (CART)  0.741935         0.685714  0.600000  0.685714   \n",
       "        Self-Training (KNN)   0.700000         0.600000  0.514286  0.542857   \n",
       "        Self-Training (NB)    0.477419         0.542857  0.542857  0.542857   \n",
       "        Self-Training (SVM)   0.664516         0.600000  0.542857  0.514286   \n",
       "        TriTraining (CART)    0.758065         0.685714  0.628571  0.600000   \n",
       "        TriTraining (KNN)     0.690323         0.571429  0.600000  0.485714   \n",
       "        TriTraining (NB)      0.625806         0.628571  0.457143  0.600000   \n",
       "        TriTraining (SVM)     0.664516         0.571429  0.514286  0.514286   \n",
       "\n",
       "                                        \n",
       "labeling_rate                     40.0  \n",
       "dataset classifier                      \n",
       "abalone Self-Training (CART)  0.181818  \n",
       "        Self-Training (KNN)   0.215311  \n",
       "        Self-Training (NB)    0.038278  \n",
       "        Self-Training (SVM)   0.184211  \n",
       "        TriTraining (CART)    0.203349  \n",
       "        TriTraining (KNN)     0.239234  \n",
       "        TriTraining (NB)      0.141148  \n",
       "        TriTraining (SVM)     0.193780  \n",
       "bupa    Self-Training (CART)  0.657143  \n",
       "        Self-Training (KNN)   0.514286  \n",
       "        Self-Training (NB)    0.514286  \n",
       "        Self-Training (SVM)   0.600000  \n",
       "        TriTraining (CART)    0.600000  \n",
       "        TriTraining (KNN)     0.485714  \n",
       "        TriTraining (NB)      0.542857  \n",
       "        TriTraining (SVM)     0.600000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, values=None, index=['dataset', 'classifier'], columns=['labeling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------\n",
    "[1]: Isaac Triguero et. al \"Self-labeled techniques for semi-supervised learning:taxonomy, software and empirical study\" 2015\n",
    "\n",
    "[2]: Yarowsky D (1995) Unsupervised word sense disambiguation rivaling supervised methods. In: Proceedings\n",
    "of the 33rd annual meeting of the association for computational linguistics, pp 189–196\n",
    "\n",
    "[3]: Zhou ZH, Li M (2005) Tri-training: exploiting unlabeled data using three classifiers. IEEE Trans Knowl\n",
    "Data Eng 17:1529–1541"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
