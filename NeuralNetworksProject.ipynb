{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project\n",
    "## Self-labeled techniques for semi-supervised learning\n",
    "<div style=\"text-align: right\">\n",
    "    Mark Laane <br />\n",
    "    Rome, 2017\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction ###\n",
    "The aim of this project is to reimplement some techniques surveyed by Isaac Triguero et. al in paper [1] and to independently reproduce the reported results. A report of the project is also provided: [Project Report](Neural Networks Project Report Mark Laane.pdf)\n",
    "\n",
    "Two self-labeled techniques are chosen from the paper: Standard Self-Training and Tri-Training. Those techniques are used on Abalone and Dermatology datasets. For implementation, Python programming language was chosen along with Pandas and Sclearn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets ###\n",
    "Two standard datasets are used: Abalone and Dermatology. The datasets are loaded from mldata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Datasets are stored in a python dictionary\n",
    "datasets = {}\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Fetch abalone dataset from mldata.org\n",
    "data = fetch_mldata(\"abalone\")\n",
    "# Preprocessing pipe for abalone dataset encodes categorical feature\n",
    "# and scales the features\n",
    "preprocessing_pipe = make_pipeline(\n",
    "    #OneHotEncoder on \"Sex\" feature\n",
    "    OneHotEncoder(categorical_features=[0], sparse=False),\n",
    "    #Scale all from 0 to 1\n",
    "    MinMaxScaler())\n",
    "# Apply preprocessing pipe to dataset and store the dataset in dict.\n",
    "datasets[\"abalone\"] = {\n",
    "    \"X\": preprocessing_pipe.fit_transform(data.data),\n",
    "    \"y\": data.target\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dermatology dataset is loaded from mldata.org and used as-is\n",
    "data = fetch_mldata(\"uci-20070111 dermatology\")\n",
    "datasets[\"dermatology\"] = {\n",
    "    \"X\": data.data[:,0:-1],\n",
    "    \"y\": data.data[:,-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classifiers ###\n",
    "3 different base classifiers are used. The base classifiers are provided by Sklearn library. The classifiers are configured according to the parameters described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Class that only holds a collection of different \n",
    "# base classifiers for usage with SSL methods.\n",
    "class base_classifiers:\n",
    "    KNN = KNeighborsClassifier(\n",
    "        n_neighbors=3,\n",
    "        metric=\"euclidean\",\n",
    "        #n_jobs=2  # Parallelize work on CPUs\n",
    "    )\n",
    "    NB = GaussianNB(\n",
    "        priors=None\n",
    "    )\n",
    "    #SVM = SVC(\n",
    "    #    C=1.0,\n",
    "    #    kernel='poly',\n",
    "    #    degree=1,\n",
    "    #    tol=0.001,\n",
    "    #)\n",
    "    CART = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        # splitter='best',\n",
    "        # max_depth=None,\n",
    "        # min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        # min_weight_fraction_leaf=0.0,\n",
    "        # max_features=None,\n",
    "        # random_state=None,\n",
    "        # max_leaf_nodes=None,\n",
    "        # min_impurity_split=1e-07,\n",
    "        # class_weight=None,\n",
    "        # presort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented self-labeled algorithms ###\n",
    "Two algorithms are implemented: Standard Self-Training and Tri Training.\n",
    "#### Standard Self-Training ####\n",
    "Implementation: [Standard Self-Training](standard_self_training.py)<br />\n",
    "The implementation is based on description of the algorithm in paper [2].\n",
    "Training an Standard Self-Training classifier is an iterative process - The base classifier is trained with initial labeled samples. Then it is used for labelling the unlabelled samples and the classifier is retrained with the most confident predictions. The process is repeated until the classifier output stabilizes.\n",
    "#### Tri-Training ###\n",
    "Implementation: [Tri-Training](tri_training.py)<br />\n",
    "The implementation is based on description of the algorithm in paper [3].\n",
    "In Tri-Training, Three base classifiers is trained on randomly subsampled sets of the labelled data. Then each of them will be iteratively trained on labeled data gained from two other base classifiers. The prediciton is made by using majority voting on three base classifiers.\n",
    "\n",
    "In total 6 different classifiers are trained - 2 techniques with 3 different base classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from standard_self_training import StandardSelfTraining\n",
    "from tri_training import TriTraining\n",
    "\n",
    "# All classifiers used for testing\n",
    "classifiers = [\n",
    "    TriTraining(\"TriTraining (KNN)\", base_classifiers.KNN),\n",
    "    TriTraining(\"TriTraining (NB)\", base_classifiers.NB),\n",
    "    #TriTraining(\"TriTraining (SVM)\", base_classifiers.SVM),\n",
    "    TriTraining(\"TriTraining (CART)\", base_classifiers.CART),\n",
    "    StandardSelfTraining(\"Self-Training (KNN)\", base_classifiers.KNN),\n",
    "    StandardSelfTraining(\"Self-Training (NB)\", base_classifiers.NB),\n",
    "    #StandardSelfTraining(\"Self-Training (SVM)\", base_classifiers.SVM),\n",
    "    StandardSelfTraining(\"Self-Training (CART)\", base_classifiers.CART)\n",
    "]\n",
    "labeling_rates = [0.10, 0.20, 0.30, 0.40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and scoring ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def _training_scoring_iteration(clf, X, y, training_index, test_index, labeling_rate):\n",
    "    \"\"\" \n",
    "    One iteration of fully training and scoring a \n",
    "    classifier on given data (one Kfold split)\n",
    "    \"\"\"\n",
    "    #Testing set is set aside.. - 1/10th of the data\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    #For generating a testing and transductive set\n",
    "    split_data = train_test_split(\n",
    "        X[training_index],\n",
    "        y[training_index],\n",
    "        test_size=labeling_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "    (X_unlabeled, X_labeled, y_unlabeled, y_labeled) = split_data\n",
    "\n",
    "    #Training set - 9/10 of data\n",
    "    X_train = np.concatenate((X_labeled, X_unlabeled))\n",
    "    y_train = np.concatenate((\n",
    "        y_labeled.astype(str),\n",
    "        np.full_like(y_unlabeled.astype(str), \"unlabeled\")\n",
    "    ))\n",
    "    \n",
    "    #Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #Score the classifier\n",
    "    transductive_score = clf.score(X_unlabeled, y_unlabeled.astype(str))\n",
    "    testing_score = clf.score(X_test, y_test.astype(str))\n",
    "    \n",
    "    return transductive_score, testing_score\n",
    "    \n",
    "def train_and_score(clf, X, y, cv, labeling_rate):\n",
    "    \"\"\"\n",
    "    Perform KFold cross-validation of a classifier on a given data\n",
    "    and labelling rate\n",
    "    \"\"\"\n",
    "    transductive_scores = []\n",
    "    testing_scores = []\n",
    "    for training_index, test_index in cv.split(X,y):\n",
    "        transductive_score, testing_score = _training_scoring_iteration(clf, X, y, training_index, test_index, labeling_rate)\n",
    "        \n",
    "        transductive_scores.append(transductive_score)\n",
    "        testing_scores.append(testing_score)\n",
    "        print(\"#\", end=\"\")\n",
    "    print()\n",
    "    return {\n",
    "        \"trans_mean\": np.mean(transductive_scores),\n",
    "        \"test_mean\": np.mean(testing_scores),\n",
    "        \"trans_std\": np.std(transductive_scores),\n",
    "        \"test_std\": np.std(testing_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriTraining (KNN)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "dataset: abalone \t\n",
      "rate: 0.1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "rate: 0.2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "rate: 0.3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "rate: 0.4 #"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "\n",
      "--------\n",
      "TriTraining (NB)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ###"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n",
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n",
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "dataset: abalone \t\n",
      "rate: 0.1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "rate: 0.2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "rate: 0.3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "rate: 0.4 ###"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "\n",
      "--------\n",
      "TriTraining (CART)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "dataset: abalone \t\n",
      "rate: 0.1 #"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "rate: 0.2 #######"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "rate: 0.3 ########"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##\n",
      "rate: 0.4 ########"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.5/site-packages/numpy/ma/core.py:3883: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  check = self.filled(0).__eq__(other)\n",
      "/home/mark/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:177: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##\n",
      "\n",
      "--------\n",
      "Self-Training (KNN)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "dataset: abalone \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "\n",
      "--------\n",
      "Self-Training (NB)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "dataset: abalone \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "\n",
      "--------\n",
      "Self-Training (CART)\n",
      "dataset: dermatology \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "dataset: abalone \t\n",
      "rate: 0.1 ##########\n",
      "rate: 0.2 ##########\n",
      "rate: 0.3 ##########\n",
      "rate: 0.4 ##########\n",
      "\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" \n",
    "The main loop for testing \n",
    "all classifiers with \n",
    "all datasets and \n",
    "all labeling rates\n",
    "\"\"\"\n",
    "results = None\n",
    "for classifier in classifiers:\n",
    "    print(classifier.name)\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        print(\"dataset:\", dataset_name, \"\\t\")\n",
    "        for labeling_rate in labeling_rates:\n",
    "            print(\"rate:\", labeling_rate, end=\" \")\n",
    "\n",
    "            test_info = { \"classifier\": classifier.name, \"dataset\":dataset_name, \"labeling_rate\":labeling_rate}\n",
    "            cv = KFold(n_splits=10, random_state=42)\n",
    "            scores = train_and_score(classifier, dataset[\"X\"], dataset[\"y\"], cv, labeling_rate)\n",
    "\n",
    "            if results is None:\n",
    "                results = pd.DataFrame([{**test_info, **scores}])\n",
    "            else:\n",
    "                results.loc[len(results.index)] = {**test_info, **scores}\n",
    "    print()\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset</th>\n",
       "      <th>labeling_rate</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>trans_mean</th>\n",
       "      <th>trans_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.060131</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.036302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.650375</td>\n",
       "      <td>0.070127</td>\n",
       "      <td>0.670488</td>\n",
       "      <td>0.028531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.083414</td>\n",
       "      <td>0.742178</td>\n",
       "      <td>0.021418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.784309</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.800408</td>\n",
       "      <td>0.028411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.184359</td>\n",
       "      <td>0.103033</td>\n",
       "      <td>0.185527</td>\n",
       "      <td>0.062670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.173551</td>\n",
       "      <td>0.101490</td>\n",
       "      <td>0.143877</td>\n",
       "      <td>0.094572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.155177</td>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.203701</td>\n",
       "      <td>0.009568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TriTraining (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.203248</td>\n",
       "      <td>0.050367</td>\n",
       "      <td>0.143520</td>\n",
       "      <td>0.094432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.304505</td>\n",
       "      <td>0.200854</td>\n",
       "      <td>0.303841</td>\n",
       "      <td>0.175848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.133559</td>\n",
       "      <td>0.102494</td>\n",
       "      <td>0.131341</td>\n",
       "      <td>0.088101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.190991</td>\n",
       "      <td>0.094325</td>\n",
       "      <td>0.225660</td>\n",
       "      <td>0.052463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.139108</td>\n",
       "      <td>0.168364</td>\n",
       "      <td>0.123478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.073991</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.043179</td>\n",
       "      <td>0.043297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.051639</td>\n",
       "      <td>0.051677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>0.053660</td>\n",
       "      <td>0.053850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TriTraining (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.104854</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>0.046911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.821922</td>\n",
       "      <td>0.090365</td>\n",
       "      <td>0.800315</td>\n",
       "      <td>0.055557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.879730</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.908905</td>\n",
       "      <td>0.026136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.888063</td>\n",
       "      <td>0.084047</td>\n",
       "      <td>0.899744</td>\n",
       "      <td>0.027704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.909835</td>\n",
       "      <td>0.063917</td>\n",
       "      <td>0.935179</td>\n",
       "      <td>0.022320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.189849</td>\n",
       "      <td>0.056379</td>\n",
       "      <td>0.179912</td>\n",
       "      <td>0.060278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.201570</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.059797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.172337</td>\n",
       "      <td>0.074017</td>\n",
       "      <td>0.197811</td>\n",
       "      <td>0.013502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TriTraining (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.164440</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.198289</td>\n",
       "      <td>0.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.494670</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.036719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.678003</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>0.673888</td>\n",
       "      <td>0.027315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.072453</td>\n",
       "      <td>0.732635</td>\n",
       "      <td>0.025003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.765165</td>\n",
       "      <td>0.073864</td>\n",
       "      <td>0.796865</td>\n",
       "      <td>0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.215711</td>\n",
       "      <td>0.063134</td>\n",
       "      <td>0.217480</td>\n",
       "      <td>0.009506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.210680</td>\n",
       "      <td>0.063786</td>\n",
       "      <td>0.216107</td>\n",
       "      <td>0.008401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.209482</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.213241</td>\n",
       "      <td>0.009116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Self-Training (KNN)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.202054</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>0.010749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.285060</td>\n",
       "      <td>0.081652</td>\n",
       "      <td>0.260744</td>\n",
       "      <td>0.054078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.194363</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.215726</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>0.035261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.080430</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.017747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>0.034251</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.011560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.070136</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.016192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Self-Training (NB)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.067502</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.067753</td>\n",
       "      <td>0.013520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734234</td>\n",
       "      <td>0.084154</td>\n",
       "      <td>0.776031</td>\n",
       "      <td>0.084967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.882658</td>\n",
       "      <td>0.093092</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.033661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.887913</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.902362</td>\n",
       "      <td>0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>dermatology</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.062707</td>\n",
       "      <td>0.932149</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.177636</td>\n",
       "      <td>0.048120</td>\n",
       "      <td>0.199894</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.188643</td>\n",
       "      <td>0.052186</td>\n",
       "      <td>0.198384</td>\n",
       "      <td>0.010321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.202030</td>\n",
       "      <td>0.014942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Self-Training (CART)</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.200624</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.196249</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              classifier      dataset  labeling_rate  test_mean  test_std  \\\n",
       "0      TriTraining (KNN)  dermatology            0.1   0.488889  0.060131   \n",
       "1      TriTraining (KNN)  dermatology            0.2   0.650375  0.070127   \n",
       "2      TriTraining (KNN)  dermatology            0.3   0.735210  0.083414   \n",
       "3      TriTraining (KNN)  dermatology            0.4   0.784309  0.085764   \n",
       "4      TriTraining (KNN)      abalone            0.1   0.184359  0.103033   \n",
       "5      TriTraining (KNN)      abalone            0.2   0.173551  0.101490   \n",
       "6      TriTraining (KNN)      abalone            0.3   0.155177  0.112807   \n",
       "7      TriTraining (KNN)      abalone            0.4   0.203248  0.050367   \n",
       "8       TriTraining (NB)  dermatology            0.1   0.304505  0.200854   \n",
       "9       TriTraining (NB)  dermatology            0.2   0.133559  0.102494   \n",
       "10      TriTraining (NB)  dermatology            0.3   0.190991  0.094325   \n",
       "11      TriTraining (NB)  dermatology            0.4   0.152102  0.139108   \n",
       "12      TriTraining (NB)      abalone            0.1   0.073991  0.039526   \n",
       "13      TriTraining (NB)      abalone            0.2   0.083090  0.059929   \n",
       "14      TriTraining (NB)      abalone            0.3   0.100075  0.047361   \n",
       "15      TriTraining (NB)      abalone            0.4   0.104854  0.037573   \n",
       "16    TriTraining (CART)  dermatology            0.1   0.821922  0.090365   \n",
       "17    TriTraining (CART)  dermatology            0.2   0.879730  0.084876   \n",
       "18    TriTraining (CART)  dermatology            0.3   0.888063  0.084047   \n",
       "19    TriTraining (CART)  dermatology            0.4   0.909835  0.063917   \n",
       "20    TriTraining (CART)      abalone            0.1   0.189849  0.056379   \n",
       "21    TriTraining (CART)      abalone            0.2   0.201570  0.057807   \n",
       "22    TriTraining (CART)      abalone            0.3   0.172337  0.074017   \n",
       "23    TriTraining (CART)      abalone            0.4   0.164440  0.068343   \n",
       "24   Self-Training (KNN)  dermatology            0.1   0.494670  0.053112   \n",
       "25   Self-Training (KNN)  dermatology            0.2   0.678003  0.086590   \n",
       "26   Self-Training (KNN)  dermatology            0.3   0.724324  0.072453   \n",
       "27   Self-Training (KNN)  dermatology            0.4   0.765165  0.073864   \n",
       "28   Self-Training (KNN)      abalone            0.1   0.215711  0.063134   \n",
       "29   Self-Training (KNN)      abalone            0.2   0.210680  0.063786   \n",
       "30   Self-Training (KNN)      abalone            0.3   0.209482  0.056126   \n",
       "31   Self-Training (KNN)      abalone            0.4   0.202054  0.058924   \n",
       "32    Self-Training (NB)  dermatology            0.1   0.285060  0.081652   \n",
       "33    Self-Training (NB)  dermatology            0.2   0.196396  0.069305   \n",
       "34    Self-Training (NB)  dermatology            0.3   0.196396  0.069305   \n",
       "35    Self-Training (NB)  dermatology            0.4   0.196396  0.069305   \n",
       "36    Self-Training (NB)      abalone            0.1   0.080430  0.027688   \n",
       "37    Self-Training (NB)      abalone            0.2   0.085939  0.034251   \n",
       "38    Self-Training (NB)      abalone            0.3   0.070136  0.027342   \n",
       "39    Self-Training (NB)      abalone            0.4   0.067502  0.027958   \n",
       "40  Self-Training (CART)  dermatology            0.1   0.734234  0.084154   \n",
       "41  Self-Training (CART)  dermatology            0.2   0.882658  0.093092   \n",
       "42  Self-Training (CART)  dermatology            0.3   0.887913  0.076882   \n",
       "43  Self-Training (CART)  dermatology            0.4   0.909910  0.062707   \n",
       "44  Self-Training (CART)      abalone            0.1   0.177636  0.048120   \n",
       "45  Self-Training (CART)      abalone            0.2   0.188643  0.052186   \n",
       "46  Self-Training (CART)      abalone            0.3   0.197740  0.042104   \n",
       "47  Self-Training (CART)      abalone            0.4   0.200624  0.049635   \n",
       "\n",
       "    trans_mean  trans_std  \n",
       "0     0.447080   0.036302  \n",
       "1     0.670488   0.028531  \n",
       "2     0.742178   0.021418  \n",
       "3     0.800408   0.028411  \n",
       "4     0.185527   0.062670  \n",
       "5     0.143877   0.094572  \n",
       "6     0.203701   0.009568  \n",
       "7     0.143520   0.094432  \n",
       "8     0.303841   0.175848  \n",
       "9     0.131341   0.088101  \n",
       "10    0.225660   0.052463  \n",
       "11    0.168364   0.123478  \n",
       "12    0.043179   0.043297  \n",
       "13    0.051639   0.051677  \n",
       "14    0.053660   0.053850  \n",
       "15    0.071561   0.046911  \n",
       "16    0.800315   0.055557  \n",
       "17    0.908905   0.026136  \n",
       "18    0.899744   0.027704  \n",
       "19    0.935179   0.022320  \n",
       "20    0.179912   0.060278  \n",
       "21    0.177374   0.059797  \n",
       "22    0.197811   0.013502  \n",
       "23    0.198289   0.013589  \n",
       "24    0.453488   0.036719  \n",
       "25    0.673888   0.027315  \n",
       "26    0.732635   0.025003  \n",
       "27    0.796865   0.032399  \n",
       "28    0.217480   0.009506  \n",
       "29    0.216107   0.008401  \n",
       "30    0.213241   0.009116  \n",
       "31    0.205958   0.010749  \n",
       "32    0.260744   0.054078  \n",
       "33    0.194363   0.012955  \n",
       "34    0.215726   0.040900  \n",
       "35    0.223930   0.035261  \n",
       "36    0.076111   0.017747  \n",
       "37    0.082600   0.011560  \n",
       "38    0.076694   0.016192  \n",
       "39    0.067753   0.013520  \n",
       "40    0.776031   0.084967  \n",
       "41    0.901316   0.033661  \n",
       "42    0.902362   0.023257  \n",
       "43    0.932149   0.023461  \n",
       "44    0.199894   0.008900  \n",
       "45    0.198384   0.010321  \n",
       "46    0.202030   0.014942  \n",
       "47    0.196249   0.009393  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">test_mean</th>\n",
       "      <th colspan=\"4\" halign=\"left\">test_std</th>\n",
       "      <th colspan=\"4\" halign=\"left\">trans_mean</th>\n",
       "      <th colspan=\"4\" halign=\"left\">trans_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>labeling_rate</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">abalone</th>\n",
       "      <th>Self-Training (CART)</th>\n",
       "      <td>0.177636</td>\n",
       "      <td>0.188643</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>0.200624</td>\n",
       "      <td>0.048120</td>\n",
       "      <td>0.052186</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.199894</td>\n",
       "      <td>0.198384</td>\n",
       "      <td>0.202030</td>\n",
       "      <td>0.196249</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.010321</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (KNN)</th>\n",
       "      <td>0.215711</td>\n",
       "      <td>0.210680</td>\n",
       "      <td>0.209482</td>\n",
       "      <td>0.202054</td>\n",
       "      <td>0.063134</td>\n",
       "      <td>0.063786</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.217480</td>\n",
       "      <td>0.216107</td>\n",
       "      <td>0.213241</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.010749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (NB)</th>\n",
       "      <td>0.080430</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>0.070136</td>\n",
       "      <td>0.067502</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.034251</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.067753</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.013520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (CART)</th>\n",
       "      <td>0.189849</td>\n",
       "      <td>0.201570</td>\n",
       "      <td>0.172337</td>\n",
       "      <td>0.164440</td>\n",
       "      <td>0.056379</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.074017</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.179912</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.197811</td>\n",
       "      <td>0.198289</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (KNN)</th>\n",
       "      <td>0.184359</td>\n",
       "      <td>0.173551</td>\n",
       "      <td>0.155177</td>\n",
       "      <td>0.203248</td>\n",
       "      <td>0.103033</td>\n",
       "      <td>0.101490</td>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.050367</td>\n",
       "      <td>0.185527</td>\n",
       "      <td>0.143877</td>\n",
       "      <td>0.203701</td>\n",
       "      <td>0.143520</td>\n",
       "      <td>0.062670</td>\n",
       "      <td>0.094572</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>0.094432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (NB)</th>\n",
       "      <td>0.073991</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>0.104854</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>0.043179</td>\n",
       "      <td>0.051639</td>\n",
       "      <td>0.053660</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>0.046911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dermatology</th>\n",
       "      <th>Self-Training (CART)</th>\n",
       "      <td>0.734234</td>\n",
       "      <td>0.882658</td>\n",
       "      <td>0.887913</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.084154</td>\n",
       "      <td>0.093092</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.062707</td>\n",
       "      <td>0.776031</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.902362</td>\n",
       "      <td>0.932149</td>\n",
       "      <td>0.084967</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (KNN)</th>\n",
       "      <td>0.494670</td>\n",
       "      <td>0.678003</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.765165</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>0.072453</td>\n",
       "      <td>0.073864</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.673888</td>\n",
       "      <td>0.732635</td>\n",
       "      <td>0.796865</td>\n",
       "      <td>0.036719</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Training (NB)</th>\n",
       "      <td>0.285060</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.196396</td>\n",
       "      <td>0.081652</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.260744</td>\n",
       "      <td>0.194363</td>\n",
       "      <td>0.215726</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>0.054078</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.035261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (CART)</th>\n",
       "      <td>0.821922</td>\n",
       "      <td>0.879730</td>\n",
       "      <td>0.888063</td>\n",
       "      <td>0.909835</td>\n",
       "      <td>0.090365</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.084047</td>\n",
       "      <td>0.063917</td>\n",
       "      <td>0.800315</td>\n",
       "      <td>0.908905</td>\n",
       "      <td>0.899744</td>\n",
       "      <td>0.935179</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.022320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (KNN)</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.650375</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.784309</td>\n",
       "      <td>0.060131</td>\n",
       "      <td>0.070127</td>\n",
       "      <td>0.083414</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.670488</td>\n",
       "      <td>0.742178</td>\n",
       "      <td>0.800408</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.028411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriTraining (NB)</th>\n",
       "      <td>0.304505</td>\n",
       "      <td>0.133559</td>\n",
       "      <td>0.190991</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.200854</td>\n",
       "      <td>0.102494</td>\n",
       "      <td>0.094325</td>\n",
       "      <td>0.139108</td>\n",
       "      <td>0.303841</td>\n",
       "      <td>0.131341</td>\n",
       "      <td>0.225660</td>\n",
       "      <td>0.168364</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>0.088101</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.123478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 test_mean                                \\\n",
       "labeling_rate                          0.1       0.2       0.3       0.4   \n",
       "dataset     classifier                                                     \n",
       "abalone     Self-Training (CART)  0.177636  0.188643  0.197740  0.200624   \n",
       "            Self-Training (KNN)   0.215711  0.210680  0.209482  0.202054   \n",
       "            Self-Training (NB)    0.080430  0.085939  0.070136  0.067502   \n",
       "            TriTraining (CART)    0.189849  0.201570  0.172337  0.164440   \n",
       "            TriTraining (KNN)     0.184359  0.173551  0.155177  0.203248   \n",
       "            TriTraining (NB)      0.073991  0.083090  0.100075  0.104854   \n",
       "dermatology Self-Training (CART)  0.734234  0.882658  0.887913  0.909910   \n",
       "            Self-Training (KNN)   0.494670  0.678003  0.724324  0.765165   \n",
       "            Self-Training (NB)    0.285060  0.196396  0.196396  0.196396   \n",
       "            TriTraining (CART)    0.821922  0.879730  0.888063  0.909835   \n",
       "            TriTraining (KNN)     0.488889  0.650375  0.735210  0.784309   \n",
       "            TriTraining (NB)      0.304505  0.133559  0.190991  0.152102   \n",
       "\n",
       "                                  test_std                                \\\n",
       "labeling_rate                          0.1       0.2       0.3       0.4   \n",
       "dataset     classifier                                                     \n",
       "abalone     Self-Training (CART)  0.048120  0.052186  0.042104  0.049635   \n",
       "            Self-Training (KNN)   0.063134  0.063786  0.056126  0.058924   \n",
       "            Self-Training (NB)    0.027688  0.034251  0.027342  0.027958   \n",
       "            TriTraining (CART)    0.056379  0.057807  0.074017  0.068343   \n",
       "            TriTraining (KNN)     0.103033  0.101490  0.112807  0.050367   \n",
       "            TriTraining (NB)      0.039526  0.059929  0.047361  0.037573   \n",
       "dermatology Self-Training (CART)  0.084154  0.093092  0.076882  0.062707   \n",
       "            Self-Training (KNN)   0.053112  0.086590  0.072453  0.073864   \n",
       "            Self-Training (NB)    0.081652  0.069305  0.069305  0.069305   \n",
       "            TriTraining (CART)    0.090365  0.084876  0.084047  0.063917   \n",
       "            TriTraining (KNN)     0.060131  0.070127  0.083414  0.085764   \n",
       "            TriTraining (NB)      0.200854  0.102494  0.094325  0.139108   \n",
       "\n",
       "                                 trans_mean                                \\\n",
       "labeling_rate                           0.1       0.2       0.3       0.4   \n",
       "dataset     classifier                                                      \n",
       "abalone     Self-Training (CART)   0.199894  0.198384  0.202030  0.196249   \n",
       "            Self-Training (KNN)    0.217480  0.216107  0.213241  0.205958   \n",
       "            Self-Training (NB)     0.076111  0.082600  0.076694  0.067753   \n",
       "            TriTraining (CART)     0.179912  0.177374  0.197811  0.198289   \n",
       "            TriTraining (KNN)      0.185527  0.143877  0.203701  0.143520   \n",
       "            TriTraining (NB)       0.043179  0.051639  0.053660  0.071561   \n",
       "dermatology Self-Training (CART)   0.776031  0.901316  0.902362  0.932149   \n",
       "            Self-Training (KNN)    0.453488  0.673888  0.732635  0.796865   \n",
       "            Self-Training (NB)     0.260744  0.194363  0.215726  0.223930   \n",
       "            TriTraining (CART)     0.800315  0.908905  0.899744  0.935179   \n",
       "            TriTraining (KNN)      0.447080  0.670488  0.742178  0.800408   \n",
       "            TriTraining (NB)       0.303841  0.131341  0.225660  0.168364   \n",
       "\n",
       "                                 trans_std                                \n",
       "labeling_rate                          0.1       0.2       0.3       0.4  \n",
       "dataset     classifier                                                    \n",
       "abalone     Self-Training (CART)  0.008900  0.010321  0.014942  0.009393  \n",
       "            Self-Training (KNN)   0.009506  0.008401  0.009116  0.010749  \n",
       "            Self-Training (NB)    0.017747  0.011560  0.016192  0.013520  \n",
       "            TriTraining (CART)    0.060278  0.059797  0.013502  0.013589  \n",
       "            TriTraining (KNN)     0.062670  0.094572  0.009568  0.094432  \n",
       "            TriTraining (NB)      0.043297  0.051677  0.053850  0.046911  \n",
       "dermatology Self-Training (CART)  0.084967  0.033661  0.023257  0.023461  \n",
       "            Self-Training (KNN)   0.036719  0.027315  0.025003  0.032399  \n",
       "            Self-Training (NB)    0.054078  0.012955  0.040900  0.035261  \n",
       "            TriTraining (CART)    0.055557  0.026136  0.027704  0.022320  \n",
       "            TriTraining (KNN)     0.036302  0.028531  0.021418  0.028411  \n",
       "            TriTraining (NB)      0.175848  0.088101  0.052463  0.123478  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, values=None, index=['dataset', 'classifier'], columns=['labeling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "[1]: Isaac Triguero et. al \"Self-labeled techniques for semi-supervised learning:taxonomy, software and empirical study\" 2015\n",
    "\n",
    "[2]: Yarowsky D (1995) Unsupervised word sense disambiguation rivaling supervised methods. In: Proceedings\n",
    "of the 33rd annual meeting of the association for computational linguistics, pp 189–196\n",
    "\n",
    "[3]: Zhou ZH, Li M (2005) Tri-training: exploiting unlabeled data using three classifiers. IEEE Trans Knowl\n",
    "Data Eng 17:1529–1541"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
